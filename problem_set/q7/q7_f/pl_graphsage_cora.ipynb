{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f08f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import random_walk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborSampler as RawNeighborSampler\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e867e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = osp.join(osp.dirname(osp.realpath('__file__')), '..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec987f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborSampler(RawNeighborSampler):\n",
    "    def sample(self, batch):\n",
    "        batch = torch.tensor(batch)\n",
    "        row, col, _ = self.adj_t.coo()\n",
    "\n",
    "        # For each node in `batch`, we sample a direct neighbor (as positive\n",
    "        # example) and a random node (as negative example):\n",
    "        pos_batch = random_walk(row, col, batch, walk_length=1,\n",
    "                                coalesced=False)[:, 1]\n",
    "\n",
    "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
    "                                  dtype=torch.long)\n",
    "\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        return super().sample(batch)\n",
    "\n",
    "\n",
    "train_loader = NeighborSampler(data.edge_index, sizes=[10, 10], batch_size=256,\n",
    "                               shuffle=True, num_nodes=data.num_nodes)\n",
    "val_loader = NeighborSampler(data.edge_index, sizes=[10, 10], batch_size=data.x.size(0),\n",
    "                               shuffle=True, num_nodes=data.num_nodes)\n",
    "test_loader = NeighborSampler(data.edge_index, sizes=[10, 10], batch_size=data.x.size(0),\n",
    "                               shuffle=True, num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd245265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, data):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.data = data\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def full_forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, n_id, adjs = batch\n",
    "        out = model(self.data.x[n_id], adjs)\n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        out = self.full_forward(self.data.x, self.data.edge_index)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(out[self.data.train_mask], self.data.y[self.data.train_mask])\n",
    "        \n",
    "        val_acc = clf.score(out[self.data.val_mask], self.data.y[self.data.val_mask])\n",
    "        self.log('val_acc', val_acc, prog_bar=True)\n",
    "        \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        out = self.full_forward(self.data.x, self.data.edge_index)\n",
    "        \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(out[self.data.train_mask], self.data.y[self.data.train_mask])\n",
    "        \n",
    "        test_acc = clf.score(out[self.data.test_mask], self.data.y[self.data.test_mask])\n",
    "        self.log('test_acc', test_acc, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a838ddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/1 [05:37<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | convs | ModuleList | 191 K \n",
      "-------------------------------------\n",
      "191 K     Trainable params\n",
      "0         Non-trainable params\n",
      "191 K     Total params\n",
      "0.767     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:658: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  category=UserWarning,\n",
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:429: UserWarning: The number of training samples (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|█████████▏| 11/12 [00:01<00:00,  6.43it/s, loss=1.41, v_num=4]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 12/12 [00:01<00:00,  6.09it/s, loss=1.41, v_num=4, val_acc=0.326]\n",
      "Epoch 1:  92%|█████████▏| 11/12 [00:01<00:00,  6.21it/s, loss=1.4, v_num=4, val_acc=0.326] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 12/12 [00:02<00:00,  5.87it/s, loss=1.4, v_num=4, val_acc=0.324]\n",
      "Epoch 2:  92%|█████████▏| 11/12 [00:01<00:00,  6.23it/s, loss=1.39, v_num=4, val_acc=0.324]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 12/12 [00:02<00:00,  5.90it/s, loss=1.39, v_num=4, val_acc=0.306]\n",
      "Epoch 3:  92%|█████████▏| 11/12 [00:01<00:00,  6.15it/s, loss=1.38, v_num=4, val_acc=0.306]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s, loss=1.38, v_num=4, val_acc=0.334]\n",
      "Epoch 4: 100%|██████████| 12/12 [00:01<00:00,  6.90it/s, loss=1.38, v_num=4, val_acc=0.334]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 12/12 [00:01<00:00,  6.00it/s, loss=1.38, v_num=4, val_acc=0.348]\n",
      "Epoch 5: 100%|██████████| 12/12 [00:01<00:00,  7.02it/s, loss=1.38, v_num=4, val_acc=0.348]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 12/12 [00:01<00:00,  6.10it/s, loss=1.38, v_num=4, val_acc=0.392]\n",
      "Epoch 6: 100%|██████████| 12/12 [00:01<00:00,  6.81it/s, loss=1.37, v_num=4, val_acc=0.392]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s, loss=1.37, v_num=4, val_acc=0.434]\n",
      "Epoch 7: 100%|██████████| 12/12 [00:01<00:00,  6.95it/s, loss=1.36, v_num=4, val_acc=0.434]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 12/12 [00:01<00:00,  6.05it/s, loss=1.36, v_num=4, val_acc=0.458]\n",
      "Epoch 8: 100%|██████████| 12/12 [00:01<00:00,  6.92it/s, loss=1.35, v_num=4, val_acc=0.458]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 12/12 [00:02<00:00,  5.98it/s, loss=1.35, v_num=4, val_acc=0.482]\n",
      "Epoch 9: 100%|██████████| 12/12 [00:01<00:00,  6.91it/s, loss=1.31, v_num=4, val_acc=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 12/12 [00:01<00:00,  6.00it/s, loss=1.31, v_num=4, val_acc=0.524]\n",
      "Epoch 10: 100%|██████████| 12/12 [00:01<00:00,  6.80it/s, loss=1.24, v_num=4, val_acc=0.524]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 12/12 [00:02<00:00,  5.89it/s, loss=1.24, v_num=4, val_acc=0.544]\n",
      "Epoch 11: 100%|██████████| 12/12 [00:01<00:00,  6.82it/s, loss=1.17, v_num=4, val_acc=0.544]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 12/12 [00:02<00:00,  5.89it/s, loss=1.17, v_num=4, val_acc=0.578]\n",
      "Epoch 12: 100%|██████████| 12/12 [00:02<00:00,  5.80it/s, loss=1.13, v_num=4, val_acc=0.578]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 12/12 [00:02<00:00,  5.13it/s, loss=1.13, v_num=4, val_acc=0.582]\n",
      "Epoch 13: 100%|██████████| 12/12 [00:01<00:00,  6.75it/s, loss=1.1, v_num=4, val_acc=0.582] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 12/12 [00:02<00:00,  5.88it/s, loss=1.1, v_num=4, val_acc=0.598]\n",
      "Epoch 14: 100%|██████████| 12/12 [00:01<00:00,  6.91it/s, loss=1.07, v_num=4, val_acc=0.598]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 12/12 [00:02<00:00,  5.99it/s, loss=1.07, v_num=4, val_acc=0.610]\n",
      "Epoch 15:  92%|█████████▏| 11/12 [00:01<00:00,  6.50it/s, loss=1.05, v_num=4, val_acc=0.610]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 12/12 [00:01<00:00,  6.12it/s, loss=1.05, v_num=4, val_acc=0.620]\n",
      "Epoch 16: 100%|██████████| 12/12 [00:01<00:00,  6.89it/s, loss=1.03, v_num=4, val_acc=0.620]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s, loss=1.03, v_num=4, val_acc=0.624]\n",
      "Epoch 17: 100%|██████████| 12/12 [00:01<00:00,  6.70it/s, loss=1.04, v_num=4, val_acc=0.624]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 12/12 [00:02<00:00,  5.80it/s, loss=1.04, v_num=4, val_acc=0.628]\n",
      "Epoch 18: 100%|██████████| 12/12 [00:01<00:00,  6.85it/s, loss=1.04, v_num=4, val_acc=0.628]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 12/12 [00:02<00:00,  5.89it/s, loss=1.04, v_num=4, val_acc=0.626]\n",
      "Epoch 19:  92%|█████████▏| 11/12 [00:01<00:00,  6.29it/s, loss=1.02, v_num=4, val_acc=0.626]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 12/12 [00:02<00:00,  5.91it/s, loss=1.02, v_num=4, val_acc=0.630]\n",
      "Epoch 20: 100%|██████████| 12/12 [00:01<00:00,  6.81it/s, loss=1.01, v_num=4, val_acc=0.630]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 12/12 [00:02<00:00,  5.92it/s, loss=1.01, v_num=4, val_acc=0.636]\n",
      "Epoch 21: 100%|██████████| 12/12 [00:01<00:00,  6.95it/s, loss=1.01, v_num=4, val_acc=0.636]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 12/12 [00:02<00:00,  5.99it/s, loss=1.01, v_num=4, val_acc=0.644]\n",
      "Epoch 22: 100%|██████████| 12/12 [00:01<00:00,  6.82it/s, loss=1.01, v_num=4, val_acc=0.644]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s, loss=1.01, v_num=4, val_acc=0.642]\n",
      "Epoch 23: 100%|██████████| 12/12 [00:01<00:00,  7.01it/s, loss=1, v_num=4, val_acc=0.642]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 12/12 [00:01<00:00,  6.08it/s, loss=1, v_num=4, val_acc=0.648]\n",
      "Epoch 24:  92%|█████████▏| 11/12 [00:01<00:00,  6.43it/s, loss=0.995, v_num=4, val_acc=0.648]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 12/12 [00:01<00:00,  6.06it/s, loss=0.995, v_num=4, val_acc=0.642]\n",
      "Epoch 25: 100%|██████████| 12/12 [00:01<00:00,  6.82it/s, loss=0.998, v_num=4, val_acc=0.642]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 12/12 [00:02<00:00,  5.86it/s, loss=0.998, v_num=4, val_acc=0.648]\n",
      "Epoch 26: 100%|██████████| 12/12 [00:01<00:00,  6.41it/s, loss=1.01, v_num=4, val_acc=0.648] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 12/12 [00:02<00:00,  5.56it/s, loss=1.01, v_num=4, val_acc=0.648]\n",
      "Epoch 27:  92%|█████████▏| 11/12 [00:01<00:00,  6.26it/s, loss=0.999, v_num=4, val_acc=0.648]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 12/12 [00:02<00:00,  5.88it/s, loss=0.999, v_num=4, val_acc=0.658]\n",
      "Epoch 28: 100%|██████████| 12/12 [00:01<00:00,  6.74it/s, loss=0.99, v_num=4, val_acc=0.658] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 12/12 [00:02<00:00,  5.85it/s, loss=0.99, v_num=4, val_acc=0.656]\n",
      "Epoch 29:  92%|█████████▏| 11/12 [00:01<00:00,  6.38it/s, loss=0.985, v_num=4, val_acc=0.656]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 12/12 [00:01<00:00,  6.02it/s, loss=0.985, v_num=4, val_acc=0.660]\n",
      "Epoch 30: 100%|██████████| 12/12 [00:01<00:00,  6.85it/s, loss=0.989, v_num=4, val_acc=0.660]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 12/12 [00:02<00:00,  5.94it/s, loss=0.989, v_num=4, val_acc=0.666]\n",
      "Epoch 31: 100%|██████████| 12/12 [00:01<00:00,  6.89it/s, loss=0.998, v_num=4, val_acc=0.666]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s, loss=0.998, v_num=4, val_acc=0.666]\n",
      "Epoch 32: 100%|██████████| 12/12 [00:01<00:00,  7.11it/s, loss=0.988, v_num=4, val_acc=0.666]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|██████████| 12/12 [00:01<00:00,  6.15it/s, loss=0.988, v_num=4, val_acc=0.660]\n",
      "Epoch 33: 100%|██████████| 12/12 [00:01<00:00,  6.91it/s, loss=0.99, v_num=4, val_acc=0.660] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 12/12 [00:02<00:00,  5.96it/s, loss=0.99, v_num=4, val_acc=0.658]\n",
      "Epoch 34: 100%|██████████| 12/12 [00:01<00:00,  6.91it/s, loss=0.981, v_num=4, val_acc=0.658]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 12/12 [00:02<00:00,  5.96it/s, loss=0.981, v_num=4, val_acc=0.660]\n",
      "Epoch 35: 100%|██████████| 12/12 [00:01<00:00,  6.75it/s, loss=0.973, v_num=4, val_acc=0.660]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 12/12 [00:02<00:00,  5.84it/s, loss=0.973, v_num=4, val_acc=0.662]\n",
      "Epoch 36: 100%|██████████| 12/12 [00:01<00:00,  6.76it/s, loss=0.97, v_num=4, val_acc=0.662] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|██████████| 12/12 [00:02<00:00,  5.84it/s, loss=0.97, v_num=4, val_acc=0.664]\n",
      "Epoch 37: 100%|██████████| 12/12 [00:01<00:00,  6.56it/s, loss=0.971, v_num=4, val_acc=0.664]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 12/12 [00:02<00:00,  5.74it/s, loss=0.971, v_num=4, val_acc=0.668]\n",
      "Epoch 38: 100%|██████████| 12/12 [00:01<00:00,  6.92it/s, loss=0.967, v_num=4, val_acc=0.668]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 12/12 [00:02<00:00,  5.99it/s, loss=0.967, v_num=4, val_acc=0.672]\n",
      "Epoch 39: 100%|██████████| 12/12 [00:01<00:00,  7.00it/s, loss=0.964, v_num=4, val_acc=0.672]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 12/12 [00:01<00:00,  6.07it/s, loss=0.964, v_num=4, val_acc=0.680]\n",
      "Epoch 40: 100%|██████████| 12/12 [00:01<00:00,  6.97it/s, loss=0.969, v_num=4, val_acc=0.680]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 12/12 [00:01<00:00,  6.02it/s, loss=0.969, v_num=4, val_acc=0.682]\n",
      "Epoch 41: 100%|██████████| 12/12 [00:01<00:00,  6.90it/s, loss=0.965, v_num=4, val_acc=0.682]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 12/12 [00:01<00:00,  6.02it/s, loss=0.965, v_num=4, val_acc=0.686]\n",
      "Epoch 42: 100%|██████████| 12/12 [00:01<00:00,  6.28it/s, loss=0.968, v_num=4, val_acc=0.686]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 12/12 [00:02<00:00,  5.24it/s, loss=0.968, v_num=4, val_acc=0.680]\n",
      "Epoch 43: 100%|██████████| 12/12 [00:01<00:00,  6.86it/s, loss=0.971, v_num=4, val_acc=0.680]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s, loss=0.971, v_num=4, val_acc=0.678]\n",
      "Epoch 44: 100%|██████████| 12/12 [00:01<00:00,  6.64it/s, loss=0.967, v_num=4, val_acc=0.678]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 12/12 [00:02<00:00,  5.74it/s, loss=0.967, v_num=4, val_acc=0.674]\n",
      "Epoch 45: 100%|██████████| 12/12 [00:01<00:00,  6.86it/s, loss=0.96, v_num=4, val_acc=0.674] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s, loss=0.96, v_num=4, val_acc=0.680]\n",
      "Epoch 46: 100%|██████████| 12/12 [00:01<00:00,  6.97it/s, loss=0.97, v_num=4, val_acc=0.680] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 12/12 [00:01<00:00,  6.03it/s, loss=0.97, v_num=4, val_acc=0.684]\n",
      "Epoch 47: 100%|██████████| 12/12 [00:01<00:00,  6.85it/s, loss=0.973, v_num=4, val_acc=0.684]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 12/12 [00:02<00:00,  5.94it/s, loss=0.973, v_num=4, val_acc=0.686]\n",
      "Epoch 48:  92%|█████████▏| 11/12 [00:01<00:00,  6.34it/s, loss=0.955, v_num=4, val_acc=0.686]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 12/12 [00:01<00:00,  6.00it/s, loss=0.955, v_num=4, val_acc=0.684]\n",
      "Epoch 49: 100%|██████████| 12/12 [00:01<00:00,  6.91it/s, loss=0.96, v_num=4, val_acc=0.684] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s, loss=0.96, v_num=4, val_acc=0.690]\n",
      "Epoch 49: 100%|██████████| 12/12 [00:02<00:00,  5.94it/s, loss=0.96, v_num=4, val_acc=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:907: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:658: UserWarning: Your `test_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  category=UserWarning,\n",
      "/home/jovyan/.conda/geo/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.7020000219345093}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.7020000219345093}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAGE(data.num_node_features, hidden_channels=64, num_layers=2, data=data)\n",
    "trainer = pl.Trainer(max_epochs=50)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afb665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
